{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DS-SF-27 | Codealong 16 | Introduction to Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## >>> One-time setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''\n",
    "import nltk\n",
    "nltk.download()\n",
    "'''\n",
    "\n",
    "pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <<< One-time setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', 10)\n",
    "pd.set_option('display.notebook_repr_html', True)\n",
    "pd.set_option('display.max_columns', 10)\n",
    "\n",
    "import string\n",
    "import unicodedata\n",
    "from nltk import tokenize, corpus, stem\n",
    "\n",
    "from sklearn import feature_extraction, linear_model, ensemble, cross_validation, metrics, decomposition\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tokenize_text(document):\n",
    "    document = document.encode('utf-8')\n",
    "\n",
    "    # Convert text to lowercase\n",
    "    document = document.lower()\n",
    "\n",
    "    # Tokenize\n",
    "    tokens = tokenize.word_tokenize(document)\n",
    "\n",
    "    # Remove punctuation in tokens and then remove empty tokens\n",
    "    tokens = [token.translate(None, string.punctuation) for token in tokens]\n",
    "    tokens = [token for token in tokens if token]\n",
    "\n",
    "    # Remove stop words\n",
    "    tokens = [token for token in tokens if not token in corpus.stopwords.words('english')]\n",
    "\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sentence', 'wait', 'another', 'third']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenize_text(\"This is a sentence...  Wait, here's another.  And a third!\")\n",
    "\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Stemmer:\n",
    "    stemmer = stem.porter.PorterStemmer()\n",
    "\n",
    "    @staticmethod\n",
    "    def stem_tokens(tokens):\n",
    "        return [Stemmer.stemmer.stem(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'sentenc', u'wait', u'anoth', u'third']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = Stemmer.stem_tokens(tokens)\n",
    "\n",
    "tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Book reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, we will be analyzing a partial list of the reviews for J.K. Rowling's The Casual Vacancy.  (https://www.amazon.com/dp/0316228532)\n",
    "\n",
    "Our dataset is a subset of http://snap.stanford.edu/data/amazon/productGraph/categoryFiles/reviews_Books_5.json.gz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join('..', 'datasets', 'reviews_Books_5-0316228532.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>asin</th>\n",
       "      <th>reviewer_id</th>\n",
       "      <th>reviewer_name</th>\n",
       "      <th>summary</th>\n",
       "      <th>review_text</th>\n",
       "      <th>overall</th>\n",
       "      <th>review_time</th>\n",
       "      <th>unix_review_time</th>\n",
       "      <th>helpful</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>316228532</td>\n",
       "      <td>AY2UIGHCB4VPB</td>\n",
       "      <td>NaN</td>\n",
       "      <td>but a good read!</td>\n",
       "      <td>A departure for her, but a good read!</td>\n",
       "      <td>5</td>\n",
       "      <td>07 12, 2014</td>\n",
       "      <td>1405123200</td>\n",
       "      <td>[0, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>316228532</td>\n",
       "      <td>A2L17U0TWH9UWS</td>\n",
       "      <td>1075</td>\n",
       "      <td>Not worth the time</td>\n",
       "      <td>I had a hard time remembering who each charact...</td>\n",
       "      <td>2</td>\n",
       "      <td>11 12, 2013</td>\n",
       "      <td>1384214400</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>316228532</td>\n",
       "      <td>A2R63TBVG5OAF6</td>\n",
       "      <td>12121</td>\n",
       "      <td>The Casual Vacancy</td>\n",
       "      <td>This is the only review I have ever written.  ...</td>\n",
       "      <td>1</td>\n",
       "      <td>10 1, 2012</td>\n",
       "      <td>1349049600</td>\n",
       "      <td>[13, 25]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>316228532</td>\n",
       "      <td>ACU39L9G696US</td>\n",
       "      <td>123esmo</td>\n",
       "      <td>Expecting more from J.K. Rowling</td>\n",
       "      <td>I was expecting more from J.K. Rowling, it's a...</td>\n",
       "      <td>2</td>\n",
       "      <td>01 10, 2013</td>\n",
       "      <td>1357776000</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>316228532</td>\n",
       "      <td>A3N7KY1PBMF880</td>\n",
       "      <td>&amp;#34;Bad Cat!&amp;#34;</td>\n",
       "      <td>Sorry That I  Bought It.</td>\n",
       "      <td>As big a fan as I am of J K Rowling's Harry Po...</td>\n",
       "      <td>1</td>\n",
       "      <td>05 11, 2013</td>\n",
       "      <td>1368230400</td>\n",
       "      <td>[0, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2045</th>\n",
       "      <td>316228532</td>\n",
       "      <td>A1SCYWLS37YR50</td>\n",
       "      <td>ZC</td>\n",
       "      <td>Spectacular prose in a rambling story</td>\n",
       "      <td>Spectacular prose in a rambling story that see...</td>\n",
       "      <td>5</td>\n",
       "      <td>02 12, 2014</td>\n",
       "      <td>1392163200</td>\n",
       "      <td>[1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2046</th>\n",
       "      <td>316228532</td>\n",
       "      <td>A1POFVVXUZR3IQ</td>\n",
       "      <td>Z Hayes</td>\n",
       "      <td>Difficult to get into, but has its moments</td>\n",
       "      <td>Although I am a great fan of the Harry Potter ...</td>\n",
       "      <td>3</td>\n",
       "      <td>07 18, 2013</td>\n",
       "      <td>1374105600</td>\n",
       "      <td>[1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2047</th>\n",
       "      <td>316228532</td>\n",
       "      <td>A1YSU2VSUJZAR5</td>\n",
       "      <td>zolteg59</td>\n",
       "      <td>The Casual Vacancy</td>\n",
       "      <td>While the story was intriguing, and I am a hug...</td>\n",
       "      <td>1</td>\n",
       "      <td>11 11, 2012</td>\n",
       "      <td>1352592000</td>\n",
       "      <td>[0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2048</th>\n",
       "      <td>316228532</td>\n",
       "      <td>A2ZF888HX9YR8E</td>\n",
       "      <td>Zoobeefoo</td>\n",
       "      <td>A better read for Brits perhaps?</td>\n",
       "      <td>What an odd book!  The adolescent characters a...</td>\n",
       "      <td>3</td>\n",
       "      <td>12 30, 2012</td>\n",
       "      <td>1356825600</td>\n",
       "      <td>[2, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2049</th>\n",
       "      <td>316228532</td>\n",
       "      <td>A3VE36BNPVYR4N</td>\n",
       "      <td>zoshi</td>\n",
       "      <td>Loved it!</td>\n",
       "      <td>Chatty and immediately comfortable to read. It...</td>\n",
       "      <td>5</td>\n",
       "      <td>10 16, 2012</td>\n",
       "      <td>1350345600</td>\n",
       "      <td>[2, 3]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2050 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           asin     reviewer_id       reviewer_name  \\\n",
       "0     316228532   AY2UIGHCB4VPB                 NaN   \n",
       "1     316228532  A2L17U0TWH9UWS                1075   \n",
       "2     316228532  A2R63TBVG5OAF6               12121   \n",
       "3     316228532   ACU39L9G696US             123esmo   \n",
       "4     316228532  A3N7KY1PBMF880  &#34;Bad Cat!&#34;   \n",
       "...         ...             ...                 ...   \n",
       "2045  316228532  A1SCYWLS37YR50                  ZC   \n",
       "2046  316228532  A1POFVVXUZR3IQ             Z Hayes   \n",
       "2047  316228532  A1YSU2VSUJZAR5            zolteg59   \n",
       "2048  316228532  A2ZF888HX9YR8E           Zoobeefoo   \n",
       "2049  316228532  A3VE36BNPVYR4N               zoshi   \n",
       "\n",
       "                                         summary  \\\n",
       "0                               but a good read!   \n",
       "1                             Not worth the time   \n",
       "2                             The Casual Vacancy   \n",
       "3               Expecting more from J.K. Rowling   \n",
       "4                       Sorry That I  Bought It.   \n",
       "...                                          ...   \n",
       "2045       Spectacular prose in a rambling story   \n",
       "2046  Difficult to get into, but has its moments   \n",
       "2047                          The Casual Vacancy   \n",
       "2048            A better read for Brits perhaps?   \n",
       "2049                                   Loved it!   \n",
       "\n",
       "                                            review_text  overall  review_time  \\\n",
       "0                 A departure for her, but a good read!        5  07 12, 2014   \n",
       "1     I had a hard time remembering who each charact...        2  11 12, 2013   \n",
       "2     This is the only review I have ever written.  ...        1   10 1, 2012   \n",
       "3     I was expecting more from J.K. Rowling, it's a...        2  01 10, 2013   \n",
       "4     As big a fan as I am of J K Rowling's Harry Po...        1  05 11, 2013   \n",
       "...                                                 ...      ...          ...   \n",
       "2045  Spectacular prose in a rambling story that see...        5  02 12, 2014   \n",
       "2046  Although I am a great fan of the Harry Potter ...        3  07 18, 2013   \n",
       "2047  While the story was intriguing, and I am a hug...        1  11 11, 2012   \n",
       "2048  What an odd book!  The adolescent characters a...        3  12 30, 2012   \n",
       "2049  Chatty and immediately comfortable to read. It...        5  10 16, 2012   \n",
       "\n",
       "      unix_review_time   helpful  \n",
       "0           1405123200    [0, 0]  \n",
       "1           1384214400    [0, 1]  \n",
       "2           1349049600  [13, 25]  \n",
       "3           1357776000    [0, 1]  \n",
       "4           1368230400    [0, 3]  \n",
       "...                ...       ...  \n",
       "2045        1392163200    [1, 1]  \n",
       "2046        1374105600    [1, 1]  \n",
       "2047        1352592000    [0, 1]  \n",
       "2048        1356825600    [2, 3]  \n",
       "2049        1350345600    [2, 3]  \n",
       "\n",
       "[2050 rows x 9 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.drop(['asin', 'reviewer_id', 'reviewer_name', 'summary', 'review_time', 'unix_review_time', 'helpful'],\n",
    "    axis = 1,\n",
    "    inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_text</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A departure for her, but a good read!</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I had a hard time remembering who each charact...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is the only review I have ever written.  ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I was expecting more from J.K. Rowling, it's a...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>As big a fan as I am of J K Rowling's Harry Po...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2045</th>\n",
       "      <td>Spectacular prose in a rambling story that see...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2046</th>\n",
       "      <td>Although I am a great fan of the Harry Potter ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2047</th>\n",
       "      <td>While the story was intriguing, and I am a hug...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2048</th>\n",
       "      <td>What an odd book!  The adolescent characters a...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2049</th>\n",
       "      <td>Chatty and immediately comfortable to read. It...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2050 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            review_text  overall\n",
       "0                 A departure for her, but a good read!        5\n",
       "1     I had a hard time remembering who each charact...        2\n",
       "2     This is the only review I have ever written.  ...        1\n",
       "3     I was expecting more from J.K. Rowling, it's a...        2\n",
       "4     As big a fan as I am of J K Rowling's Harry Po...        1\n",
       "...                                                 ...      ...\n",
       "2045  Spectacular prose in a rambling story that see...        5\n",
       "2046  Although I am a great fan of the Harry Potter ...        3\n",
       "2047  While the story was intriguing, and I am a hug...        1\n",
       "2048  What an odd book!  The adolescent characters a...        3\n",
       "2049  Chatty and immediately comfortable to read. It...        5\n",
       "\n",
       "[2050 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    464\n",
       "5    457\n",
       "3    397\n",
       "2    373\n",
       "1    359\n",
       "Name: overall, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.overall.value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review_text    0\n",
       "overall        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO\n",
    "# check empty string\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define feature matrix\n",
    "X = df.review_text\n",
    "c = df.overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       5\n",
       "1       2\n",
       "2       1\n",
       "3       2\n",
       "4       1\n",
       "       ..\n",
       "2045    5\n",
       "2046    3\n",
       "2047    1\n",
       "2048    3\n",
       "2049    5\n",
       "Name: overall, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#todo\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                   A departure for her, but a good read!\n",
       "1       I had a hard time remembering who each charact...\n",
       "2       This is the only review I have ever written.  ...\n",
       "3       I was expecting more from J.K. Rowling, it's a...\n",
       "4       As big a fan as I am of J K Rowling's Harry Po...\n",
       "                              ...                        \n",
       "2045    Spectacular prose in a rambling story that see...\n",
       "2046    Although I am a great fan of the Harry Potter ...\n",
       "2047    While the story was intriguing, and I am a hug...\n",
       "2048    What an odd book!  The adolescent characters a...\n",
       "2049    Chatty and immediately comfortable to read. It...\n",
       "Name: review_text, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to do\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_X, test_X, train_c, test_c = cross_validation.train_test_split(X, c, train_size = .6, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "970     Don't let anyone kid you: there's magic in J.K...\n",
       "494     JK Rowling can write, no one doubts that.  But...\n",
       "580     Just because everything has been said about a ...\n",
       "1038    I was initially intruiged by the summary on th...\n",
       "1185    An excellent story line. Well written with goo...\n",
       "                              ...                        \n",
       "1383    I loved the writing in Harry Potter and I am n...\n",
       "1731    Even though I knew this would be nothing like ...\n",
       "763     It took me a while to start to get the large c...\n",
       "835     Try to think of this is a &#34;first novel,&#3...\n",
       "1653    (yes, I am a Harry Potter fan)I found the pola...\n",
       "Name: review_text, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## TF-IDF and `TfidfVectorizer`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "# similar to scaler\n",
    "'''\n",
    "vectorizer = feature_extraction.text.TfidfVectorizer(stop_words = 'english')\n",
    "'''\n",
    "\n",
    "class CustomTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.stemmer = stem.porter.PorterStemmer()\n",
    "\n",
    "    def __call__(self, document):\n",
    "        tokens = tokenize_text(document)\n",
    "        tokens = Stemmer.stem_tokens(tokens)\n",
    "        return tokens\n",
    "\n",
    "vectorizer = feature_extraction.text.TfidfVectorizer(tokenizer = CustomTokenizer(), ngram_range = (1, 3), min_df = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "vectorizer.fit(train_X)\n",
    "\n",
    "pass\n",
    "# going to create collumn for each\n",
    "# fit train the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag-of-words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'1',\n",
       " u'1 star',\n",
       " u'10',\n",
       " u'100',\n",
       " u'100 page',\n",
       " u'12',\n",
       " u'12 star',\n",
       " u'13',\n",
       " u'14',\n",
       " u'15',\n",
       " u'150',\n",
       " u'150 page',\n",
       " u'16',\n",
       " u'1799',\n",
       " u'18',\n",
       " u'1984',\n",
       " u'19th',\n",
       " u'1star',\n",
       " u'1star review',\n",
       " u'2',\n",
       " u'2 star',\n",
       " u'20',\n",
       " u'200',\n",
       " u'200 page',\n",
       " u'2012',\n",
       " u'23',\n",
       " u'25',\n",
       " u'3',\n",
       " u'3 star',\n",
       " u'30',\n",
       " u'300',\n",
       " u'300 page',\n",
       " u'34',\n",
       " u'34 34',\n",
       " u'34 adult',\n",
       " u'34 adult 34',\n",
       " u'34 bad',\n",
       " u'34 book',\n",
       " u'34 casual',\n",
       " u'34 casual vacanc',\n",
       " u'34 charact',\n",
       " u'34 enjoy',\n",
       " u'34 f',\n",
       " u'34 f 34',\n",
       " u'34 get',\n",
       " u'34 good',\n",
       " u'34 harri',\n",
       " u'34 harri potter',\n",
       " u'34 novel',\n",
       " u'34 plot',\n",
       " u'34 real',\n",
       " u'34 town',\n",
       " u'34 word',\n",
       " u'35',\n",
       " u'35 star',\n",
       " u'3rd',\n",
       " u'4',\n",
       " u'4 5',\n",
       " u'4 5 star',\n",
       " u'4 letter',\n",
       " u'4 letter word',\n",
       " u'4 star',\n",
       " u'40',\n",
       " u'400',\n",
       " u'400 page',\n",
       " u'45',\n",
       " u'5',\n",
       " u'5 star',\n",
       " u'50',\n",
       " u'50 page',\n",
       " u'500',\n",
       " u'500 page',\n",
       " u'503',\n",
       " u'503 page',\n",
       " u'512',\n",
       " u'6',\n",
       " u'60',\n",
       " u'7',\n",
       " u'70',\n",
       " u'8',\n",
       " u'80',\n",
       " u'8211',\n",
       " u'8217',\n",
       " u'8217 one',\n",
       " u'8217 read',\n",
       " u'8220',\n",
       " u'8221',\n",
       " u'abandon',\n",
       " u'abbey',\n",
       " u'abil',\n",
       " u'abil creat',\n",
       " u'abil weav',\n",
       " u'abject',\n",
       " u'abl',\n",
       " u'abl get',\n",
       " u'abl put',\n",
       " u'abrupt',\n",
       " u'abruptli',\n",
       " u'absolut',\n",
       " u'absolut love',\n",
       " u'absorb',\n",
       " u'abund',\n",
       " u'abus',\n",
       " u'abus drug',\n",
       " u'accent',\n",
       " u'accept',\n",
       " u'access',\n",
       " u'accomplish',\n",
       " u'account',\n",
       " u'accur',\n",
       " u'accus',\n",
       " u'achiev',\n",
       " u'acknowledg',\n",
       " u'acquaint',\n",
       " u'across',\n",
       " u'act',\n",
       " u'act like',\n",
       " u'action',\n",
       " u'action book',\n",
       " u'activ',\n",
       " u'actor',\n",
       " u'actual',\n",
       " u'actual care',\n",
       " u'actual found',\n",
       " u'actual like',\n",
       " u'actual plot',\n",
       " u'actual read',\n",
       " u'actual write',\n",
       " u'acut',\n",
       " u'ad',\n",
       " u'adapt',\n",
       " u'add',\n",
       " u'add anyth',\n",
       " u'addict',\n",
       " u'addict clinic',\n",
       " u'addict mother',\n",
       " u'addict terri',\n",
       " u'addit',\n",
       " u'address',\n",
       " u'adject',\n",
       " u'adjust',\n",
       " u'administr',\n",
       " u'admir',\n",
       " u'admir j',\n",
       " u'admir j k',\n",
       " u'admir jk',\n",
       " u'admit',\n",
       " u'admit nt',\n",
       " u'adolesc',\n",
       " u'adopt',\n",
       " u'ador',\n",
       " u'adult',\n",
       " u'adult 34',\n",
       " u'adult audienc',\n",
       " u'adult book',\n",
       " u'adult book disappoint',\n",
       " u'adult book like',\n",
       " u'adult book would',\n",
       " u'adult charact',\n",
       " u'adult children',\n",
       " u'adult content',\n",
       " u'adult fiction',\n",
       " u'adult get',\n",
       " u'adult harri',\n",
       " u'adult harri potter',\n",
       " u'adult issu',\n",
       " u'adult languag',\n",
       " u'adult love',\n",
       " u'adult market',\n",
       " u'adult novel',\n",
       " u'adult novel jk',\n",
       " u'adult nt',\n",
       " u'adult read',\n",
       " u'adult rowl',\n",
       " u'adult sex',\n",
       " u'adult situat',\n",
       " u'adult stori',\n",
       " u'adult theme',\n",
       " u'adult well',\n",
       " u'adult would',\n",
       " u'adulteri',\n",
       " u'adultsi',\n",
       " u'advantag',\n",
       " u'adventur',\n",
       " u'advertis',\n",
       " u'advic',\n",
       " u'advoc',\n",
       " u'affair',\n",
       " u'affect',\n",
       " u'affect live',\n",
       " u'aforement',\n",
       " u'afraid',\n",
       " u'afternoon',\n",
       " u'agatha',\n",
       " u'agatha christi',\n",
       " u'age',\n",
       " u'agenda',\n",
       " u'aggress',\n",
       " u'ago',\n",
       " u'agre',\n",
       " u'ah',\n",
       " u'ahead',\n",
       " u'aim',\n",
       " u'air',\n",
       " u'airport',\n",
       " u'ala',\n",
       " u'albeit',\n",
       " u'alcohol',\n",
       " u'alert',\n",
       " u'alien',\n",
       " u'align',\n",
       " u'alik',\n",
       " u'aliv',\n",
       " u'allegi',\n",
       " u'allianc',\n",
       " u'allow',\n",
       " u'almost',\n",
       " u'almost everi',\n",
       " u'almost feel',\n",
       " u'almost gave',\n",
       " u'almost like',\n",
       " u'almost need',\n",
       " u'alon',\n",
       " u'along',\n",
       " u'along line',\n",
       " u'along nt',\n",
       " u'alot',\n",
       " u'alreadi',\n",
       " u'alreadi know',\n",
       " u'also',\n",
       " u'also enjoy',\n",
       " u'also found',\n",
       " u'also got',\n",
       " u'also love',\n",
       " u'also made',\n",
       " u'also nt',\n",
       " u'also read',\n",
       " u'also show',\n",
       " u'also stori',\n",
       " u'also thought',\n",
       " u'also want',\n",
       " u'altern',\n",
       " u'although',\n",
       " u'altogeth',\n",
       " u'alway',\n",
       " u'alway interest',\n",
       " u'alway like',\n",
       " u'alway nice',\n",
       " u'amaz',\n",
       " u'amaz stori',\n",
       " u'amaz writer',\n",
       " u'amazingli',\n",
       " u'amazon',\n",
       " u'amazon review',\n",
       " u'ambit',\n",
       " u'ambiti',\n",
       " u'america',\n",
       " u'american',\n",
       " u'american reader',\n",
       " u'amidst',\n",
       " u'among',\n",
       " u'among charact',\n",
       " u'amongst',\n",
       " u'amount',\n",
       " u'amount charact',\n",
       " u'amus',\n",
       " u'analysi',\n",
       " u'analyz',\n",
       " u'ancient',\n",
       " u'ancient abbey',\n",
       " u'andor',\n",
       " u'andrew',\n",
       " u'andrew stuart',\n",
       " u'aneur',\n",
       " u'aneurysm',\n",
       " u'angel',\n",
       " u'anger',\n",
       " u'angl',\n",
       " u'angri',\n",
       " u'angst',\n",
       " u'anniversari',\n",
       " u'announc',\n",
       " u'annoy',\n",
       " u'anoth',\n",
       " u'anoth adult',\n",
       " u'anoth author',\n",
       " u'anoth book',\n",
       " u'anoth charact',\n",
       " u'anoth good',\n",
       " u'anoth harri',\n",
       " u'anoth harri potter',\n",
       " u'anoth nt',\n",
       " u'anoth one',\n",
       " u'anoth tri',\n",
       " u'answer',\n",
       " u'antagonist',\n",
       " u'anticip',\n",
       " u'antithesi',\n",
       " u'anxiou',\n",
       " u'anymor',\n",
       " u'anyon',\n",
       " u'anyon els',\n",
       " u'anyon like',\n",
       " u'anyon read',\n",
       " u'anyth',\n",
       " u'anyth els',\n",
       " u'anyth like',\n",
       " u'anyth like harri',\n",
       " u'anyth read',\n",
       " u'anyth stori',\n",
       " u'anyth write',\n",
       " u'anyway',\n",
       " u'anywher',\n",
       " u'apart',\n",
       " u'appal',\n",
       " u'appar',\n",
       " u'appeal',\n",
       " u'appeal reader',\n",
       " u'appear',\n",
       " u'appl',\n",
       " u'appl orang',\n",
       " u'applaud',\n",
       " u'appli',\n",
       " u'appreci',\n",
       " u'approach',\n",
       " u'appropri',\n",
       " u'approxim',\n",
       " u'apt',\n",
       " u'area',\n",
       " u'arf',\n",
       " u'argu',\n",
       " u'argument',\n",
       " u'aris',\n",
       " u'around',\n",
       " u'around us',\n",
       " u'array',\n",
       " u'array charact',\n",
       " u'arrog',\n",
       " u'art',\n",
       " u'artist',\n",
       " u'asid',\n",
       " u'ask',\n",
       " u'asleep',\n",
       " u'aspect',\n",
       " u'assembl',\n",
       " u'assign',\n",
       " u'assist',\n",
       " u'assum',\n",
       " u'assumpt',\n",
       " u'astound',\n",
       " u'astut',\n",
       " u'astut observ',\n",
       " u'atmospher',\n",
       " u'attach',\n",
       " u'attack',\n",
       " u'attempt',\n",
       " u'attempt read',\n",
       " u'attend',\n",
       " u'attent',\n",
       " u'attitud',\n",
       " u'attract',\n",
       " u'audienc',\n",
       " u'audio',\n",
       " u'audio version',\n",
       " u'audiobook',\n",
       " u'austen',\n",
       " u'authent',\n",
       " u'author',\n",
       " u'author book',\n",
       " u'author complet',\n",
       " u'author creat',\n",
       " u'author expect',\n",
       " u'author great',\n",
       " u'author harri',\n",
       " u'author harri potter',\n",
       " u'author jk',\n",
       " u'author jk rowl',\n",
       " u'author must',\n",
       " u'author new',\n",
       " u'author new book',\n",
       " u'author read',\n",
       " u'author realli',\n",
       " u'author seem',\n",
       " u'author skill',\n",
       " u'author take',\n",
       " u'author talent',\n",
       " u'author tri',\n",
       " u'author want',\n",
       " u'author work',\n",
       " u'author would',\n",
       " u'author write',\n",
       " u'author written',\n",
       " u'author wrote',\n",
       " u'avail',\n",
       " u'averag',\n",
       " u'avid',\n",
       " u'avid harri',\n",
       " u'avid harri potter',\n",
       " u'avoid',\n",
       " u'aw',\n",
       " u'await',\n",
       " u'awar',\n",
       " u'away',\n",
       " u'awe',\n",
       " u'awesom',\n",
       " u'awhil',\n",
       " u'awhil get',\n",
       " u'awhil get book',\n",
       " u'awkward',\n",
       " u'b',\n",
       " u'babi',\n",
       " u'back',\n",
       " u'back book',\n",
       " u'back check',\n",
       " u'back children',\n",
       " u'back finish',\n",
       " u'back forth',\n",
       " u'back harri',\n",
       " u'back read',\n",
       " u'back reread',\n",
       " u'back stori',\n",
       " u'back world',\n",
       " u'background',\n",
       " u'backstab',\n",
       " u'backstori',\n",
       " u'bad',\n",
       " u'bad book',\n",
       " u'bad decis',\n",
       " u'bad guy',\n",
       " u'bad languag',\n",
       " u'bad thing',\n",
       " u'badli',\n",
       " u'badli written',\n",
       " u'bag',\n",
       " u'balanc',\n",
       " u'ball',\n",
       " u'banal',\n",
       " u'band',\n",
       " u'bare',\n",
       " u'barri',\n",
       " u'barri death',\n",
       " u'barri fairbroth',\n",
       " u'barri fairbroth death',\n",
       " u'barri fairbroth die',\n",
       " u'barri fairbroth drop',\n",
       " u'barri fairweath',\n",
       " u'base',\n",
       " u'basi',\n",
       " u'basic',\n",
       " u'battl',\n",
       " u'bbc',\n",
       " u'be',\n",
       " u'beach',\n",
       " u'bear',\n",
       " u'beat',\n",
       " u'beauti',\n",
       " u'beauti descript',\n",
       " u'beauti write',\n",
       " u'beauti written',\n",
       " u'becam',\n",
       " u'becom',\n",
       " u'becom clear',\n",
       " u'began',\n",
       " u'begin',\n",
       " u'begin book',\n",
       " u'begin end',\n",
       " u'begin like',\n",
       " u'begin middl',\n",
       " u'begin middl end',\n",
       " u'begin novel',\n",
       " u'behav',\n",
       " u'behavior',\n",
       " u'behind',\n",
       " u'behind close',\n",
       " u'behind close door',\n",
       " u'belief',\n",
       " u'believ',\n",
       " u'believ charact',\n",
       " u'believ person',\n",
       " u'believ stori',\n",
       " u'believ would',\n",
       " u'bellchapel',\n",
       " u'belov',\n",
       " u'beneath',\n",
       " u'benefit',\n",
       " u'besid',\n",
       " u'best',\n",
       " u'best seller',\n",
       " u'best think',\n",
       " u'bestsel',\n",
       " u'betray',\n",
       " u'better',\n",
       " u'better book',\n",
       " u'better harri',\n",
       " u'better life',\n",
       " u'better stori',\n",
       " u'better word',\n",
       " u'beyond',\n",
       " u'bias',\n",
       " u'bibl',\n",
       " u'big',\n",
       " u'big fan',\n",
       " u'big fan harri',\n",
       " u'big harri',\n",
       " u'big harri potter',\n",
       " u'bigger',\n",
       " u'biggest',\n",
       " u'bigotri',\n",
       " u'binchi',\n",
       " u'bit',\n",
       " u'bit depress',\n",
       " u'bit disappoint',\n",
       " u'bit hard',\n",
       " u'bit much',\n",
       " u'bit rowl',\n",
       " u'bit slow',\n",
       " u'bit time',\n",
       " u'bite',\n",
       " u'bitter',\n",
       " u'bitter end',\n",
       " u'black',\n",
       " u'black comedi',\n",
       " u'black white',\n",
       " u'bland',\n",
       " u'bleak',\n",
       " u'bleak book',\n",
       " u'bleaker',\n",
       " u'blend',\n",
       " u'blight',\n",
       " u'blockbust',\n",
       " u'blog',\n",
       " u'blood',\n",
       " u'blown',\n",
       " u'blown away',\n",
       " u'board',\n",
       " u'board school',\n",
       " u'bodi',\n",
       " u'bog',\n",
       " u'bog mani',\n",
       " u'bog mani charact',\n",
       " u'bold',\n",
       " u'bomb',\n",
       " u'book',\n",
       " u'book 1',\n",
       " u'book 34',\n",
       " u'book 500',\n",
       " u'book 500 page',\n",
       " u'book 8217',\n",
       " u'book 8217 read',\n",
       " u'book absolut',\n",
       " u'book actual',\n",
       " u'book adult',\n",
       " u'book adult book',\n",
       " u'book almost',\n",
       " u'book also',\n",
       " u'book although',\n",
       " u'book alway',\n",
       " u'book amaz',\n",
       " u'book anyon',\n",
       " u'book anyth',\n",
       " u'book anyth like',\n",
       " u'book attempt',\n",
       " u'book author',\n",
       " u'book aw',\n",
       " u'book bad',\n",
       " u'book barri',\n",
       " u'book base',\n",
       " u'book becom',\n",
       " u'book begin',\n",
       " u'book better',\n",
       " u'book bit',\n",
       " u'book book',\n",
       " u'book bore',\n",
       " u'book bought',\n",
       " u'book ca',\n",
       " u'book ca nt',\n",
       " u'book came',\n",
       " u'book care',\n",
       " u'book casual',\n",
       " u'book casual vacanc',\n",
       " u'book certainli',\n",
       " u'book charact',\n",
       " u'book charact book',\n",
       " u'book children',\n",
       " u'book club',\n",
       " u'book club select',\n",
       " u'book come',\n",
       " u'book complet',\n",
       " u'book contain',\n",
       " u'book could',\n",
       " u'book could nt',\n",
       " u'book curiou',\n",
       " u'book dark',\n",
       " u'book day',\n",
       " u'book deal',\n",
       " u'book death',\n",
       " u'book definit',\n",
       " u'book depress',\n",
       " u'book deserv',\n",
       " u'book differ',\n",
       " u'book difficult',\n",
       " u'book disappoint',\n",
       " u'book done',\n",
       " u'book easi',\n",
       " u'book easi read',\n",
       " u'book end',\n",
       " u'book enjoy',\n",
       " u'book entertain',\n",
       " u'book even',\n",
       " u'book even though',\n",
       " u'book ever',\n",
       " u'book ever read',\n",
       " u'book everyon',\n",
       " u'book excel',\n",
       " u'book excit',\n",
       " u'book expect',\n",
       " u'book expect harri',\n",
       " u'book extrem',\n",
       " u'book fact',\n",
       " u'book fan',\n",
       " u'book far',\n",
       " u'book fascin',\n",
       " u'book feel',\n",
       " u'book feel like',\n",
       " u'book felt',\n",
       " u'book felt like',\n",
       " u'book fill',\n",
       " u'book find',\n",
       " u'book finish',\n",
       " u'book first',\n",
       " u'book follow',\n",
       " u'book found',\n",
       " u'book four',\n",
       " u'book friend',\n",
       " u'book full',\n",
       " u'book funni',\n",
       " u'book futur',\n",
       " u'book gave',\n",
       " u'book get',\n",
       " u'book gift',\n",
       " u'book give',\n",
       " u'book glad',\n",
       " u'book go',\n",
       " u'book go differ',\n",
       " u'book good',\n",
       " u'book got',\n",
       " u'book great',\n",
       " u'book gritti',\n",
       " u'book guess',\n",
       " u'book happen',\n",
       " u'book happi',\n",
       " u'book hard',\n",
       " u'book hard get',\n",
       " u'book hard read',\n",
       " u'book harri',\n",
       " u'book harri potter',\n",
       " u'book heavi',\n",
       " u'book high',\n",
       " u'book hit',\n",
       " u'book hope',\n",
       " u'book horribl',\n",
       " u'book howev',\n",
       " u'book hp',\n",
       " u'book huge',\n",
       " u'book impress',\n",
       " u'book includ',\n",
       " u'book instead',\n",
       " u'book interest',\n",
       " u'book intrigu',\n",
       " u'book jk',\n",
       " u'book jk rowl',\n",
       " u'book jkr',\n",
       " u'book keep',\n",
       " u'book kept',\n",
       " u'book kid',\n",
       " u'book kind',\n",
       " u'book kindl',\n",
       " u'book knew',\n",
       " u'book know',\n",
       " u'book languag',\n",
       " u'book last',\n",
       " u'book learn',\n",
       " u'book least',\n",
       " u'book leav',\n",
       " u'book left',\n",
       " u'book less',\n",
       " u'book let',\n",
       " u'book librari',\n",
       " u'book like',\n",
       " u'book like book',\n",
       " u'book like charact',\n",
       " u'book littl',\n",
       " u'book long',\n",
       " u'book look',\n",
       " u'book look forward',\n",
       " u'book lot',\n",
       " u'book lot charact',\n",
       " u'book love',\n",
       " u'book made',\n",
       " u'book main',\n",
       " u'book main charact',\n",
       " u'book make',\n",
       " u'book mani',\n",
       " u'book mani charact',\n",
       " u'book may',\n",
       " u'book mayb',\n",
       " u'book mean',\n",
       " u'book mention',\n",
       " u'book merit',\n",
       " u'book might',\n",
       " u'book mostli',\n",
       " u'book much',\n",
       " u'book need',\n",
       " u'book neg',\n",
       " u'book never',\n",
       " u'book noth',\n",
       " u'book noth like',\n",
       " u'book nt',\n",
       " u'book nt even',\n",
       " u'book nt expect',\n",
       " u'book nt like',\n",
       " u'book nt read',\n",
       " u'book nt want',\n",
       " u'book often',\n",
       " u'book okay',\n",
       " u'book one',\n",
       " u'book open',\n",
       " u'book overal',\n",
       " u'book page',\n",
       " u'book pain',\n",
       " u'book peopl',\n",
       " u'book perfect',\n",
       " u'book plot',\n",
       " u'book polar',\n",
       " u'book polit',\n",
       " u'book possibl',\n",
       " u'book pretti',\n",
       " u'book probabl',\n",
       " u'book problem',\n",
       " u'book put',\n",
       " u'book quit',\n",
       " u'book rate',\n",
       " u'book read',\n",
       " u'book read like',\n",
       " u'book reader',\n",
       " u'book realli',\n",
       " u'book realli nt',\n",
       " u'book reason',\n",
       " u'book receiv',\n",
       " u'book recommend',\n",
       " u'book redeem',\n",
       " u'book rememb',\n",
       " u'book remind',\n",
       " u'book review',\n",
       " u'book right',\n",
       " u'book rowl',\n",
       " u'book sad',\n",
       " u'book said',\n",
       " u'book say',\n",
       " u'book see',\n",
       " u'book seem',\n",
       " u'book seen',\n",
       " u'book seen movi',\n",
       " u'book seri',\n",
       " u'book set',\n",
       " u'book sever',\n",
       " u'book show',\n",
       " u'book simpli',\n",
       " u'book sinc',\n",
       " u'book slow',\n",
       " u'book slow start',\n",
       " u'book small',\n",
       " u'book small town',\n",
       " u'book someon',\n",
       " u'book sorri',\n",
       " u'book start',\n",
       " u'book start slow',\n",
       " u'book still',\n",
       " u'book stori',\n",
       " u'book strength',\n",
       " u'book struggl',\n",
       " u'book sure',\n",
       " u'book surpris',\n",
       " u'book take',\n",
       " u'book take long',\n",
       " u'book taken',\n",
       " u'book teenag',\n",
       " u'book tell',\n",
       " u'book think',\n",
       " u'book thoroughli',\n",
       " u'book though',\n",
       " u'book thought',\n",
       " u'book thought would',\n",
       " u'book three',\n",
       " u'book time',\n",
       " u'book told',\n",
       " u'book took',\n",
       " u'book total',\n",
       " u'book tri',\n",
       " u'book truli',\n",
       " u'book two',\n",
       " u'book uplift',\n",
       " u'book wait',\n",
       " u'book want',\n",
       " u'book wast',\n",
       " u'book way',\n",
       " u'book well',\n",
       " u'book well written',\n",
       " u'book went',\n",
       " u'book without',\n",
       " u'book wonder',\n",
       " u'book work',\n",
       " u'book worth',\n",
       " u'book would',\n",
       " u'book write',\n",
       " u'book written',\n",
       " u'book written adult',\n",
       " u'book written author',\n",
       " u'book written jk',\n",
       " u'book ye',\n",
       " u'book young',\n",
       " u'booki',\n",
       " u'bookit',\n",
       " u'bookstor',\n",
       " u'bookth',\n",
       " u'bookth book',\n",
       " u'border',\n",
       " u'bore',\n",
       " u'bore book',\n",
       " u'bore bore',\n",
       " u'bore bore bore',\n",
       " u'bore could',\n",
       " u'bore nt',\n",
       " u'bore read',\n",
       " u'bore stori',\n",
       " u'bore uninterest',\n",
       " u'borrow',\n",
       " u'bother',\n",
       " u'bother read',\n",
       " u'bottom',\n",
       " u'bought',\n",
       " u'bought book',\n",
       " u'bound',\n",
       " u'bow',\n",
       " u'boy',\n",
       " u'boy band',\n",
       " u'brain',\n",
       " u'branch',\n",
       " u'brave',\n",
       " u'bravo',\n",
       " u'breadth',\n",
       " u'break',\n",
       " u'brief',\n",
       " u'bright',\n",
       " u'brillianc',\n",
       " u'brilliant',\n",
       " u'brilliant writer',\n",
       " u'brilliantli',\n",
       " u'brilliantli written',\n",
       " u'bring',\n",
       " u'bring stori',\n",
       " u'bring togeth',\n",
       " u'bring us',\n",
       " u'bring worst',\n",
       " u'brit',\n",
       " u'britain',\n",
       " u'british',\n",
       " u'british life',\n",
       " u'british slang',\n",
       " u'british town',\n",
       " u'british villag',\n",
       " u'broad',\n",
       " u'broke',\n",
       " u'broken',\n",
       " u'brother',\n",
       " u'brought',\n",
       " u'brown',\n",
       " u'brutal',\n",
       " u'build',\n",
       " u'built',\n",
       " u'bulli',\n",
       " u'bunch',\n",
       " u'burden',\n",
       " u'busi',\n",
       " u'buy',\n",
       " u'buy book',\n",
       " u'c',\n",
       " u'ca',\n",
       " u'ca nt',\n",
       " u'ca nt believ',\n",
       " u'ca nt compar',\n",
       " u'ca nt even',\n",
       " u'ca nt get',\n",
       " u'ca nt help',\n",
       " u'ca nt imagin',\n",
       " u'ca nt put',\n",
       " u'ca nt say',\n",
       " u'ca nt wait',\n",
       " u'call',\n",
       " u'call field',\n",
       " u'call pagford',\n",
       " u'came',\n",
       " u'came finish',\n",
       " u'came togeth',\n",
       " u'camp',\n",
       " u'campaign',\n",
       " u'candid',\n",
       " u'capabl',\n",
       " u'capabl creat',\n",
       " u'captiv',\n",
       " u'captur',\n",
       " u'captur way',\n",
       " u'car',\n",
       " u'cardboard',\n",
       " u'cardboard cutout',\n",
       " u'care',\n",
       " u'care book',\n",
       " u'care charact',\n",
       " u'care enough',\n",
       " u'care happen',\n",
       " u'care much',\n",
       " u'care stori',\n",
       " u'career',\n",
       " u'caricatur',\n",
       " u'carri',\n",
       " u'case',\n",
       " u'cast',\n",
       " u'cast charact',\n",
       " u'casual',\n",
       " u'casual vacanc',\n",
       " u'casual vacanc 34',\n",
       " u'casual vacanc charact',\n",
       " u'casual vacanc could',\n",
       " u'casual vacanc far',\n",
       " u'casual vacanc feel',\n",
       " u'casual vacanc good',\n",
       " u'casual vacanc harri',\n",
       " u'casual vacanc jk',\n",
       " u'casual vacanc like',\n",
       " u'casual vacanc love',\n",
       " u'casual vacanc nt',\n",
       " u'casual vacanc parish',\n",
       " u'casual vacanc realli',\n",
       " u'casual vacanc rowl',\n",
       " u'casual vacanc show',\n",
       " u'casual vacanc think',\n",
       " u'casual vacanc took',\n",
       " u'catalyst',\n",
       " u'catastroph',\n",
       " u'catcher',\n",
       " u'catcher rye',\n",
       " u'categori',\n",
       " u'caught',\n",
       " u'caus',\n",
       " u'cd',\n",
       " u'celebr',\n",
       " u'cent',\n",
       " u'center',\n",
       " u'center around',\n",
       " u'centr',\n",
       " u'central',\n",
       " u'central charact',\n",
       " u'centuri',\n",
       " u'certain',\n",
       " u'certain charact',\n",
       " u'certainli',\n",
       " u'certainli good',\n",
       " u'chain',\n",
       " u'chain reaction',\n",
       " u'challeng',\n",
       " u'champion',\n",
       " u'chanc',\n",
       " u'chang',\n",
       " u'chang genr',\n",
       " u'chang live',\n",
       " u'chao',\n",
       " u'chapter',\n",
       " u'chapter one',\n",
       " u'chapter read',\n",
       " u'charact',\n",
       " u'charact 34',\n",
       " u'charact 8217',\n",
       " u'charact almost',\n",
       " u'charact also',\n",
       " u'charact anoth',\n",
       " u'charact author',\n",
       " u'charact becom',\n",
       " u'charact begin',\n",
       " u'charact believ',\n",
       " u'charact better',\n",
       " u'charact bit',\n",
       " u'charact book',\n",
       " u'charact book nt',\n",
       " u'charact care',\n",
       " u'charact care book',\n",
       " u'charact casual',\n",
       " u'charact casual vacanc',\n",
       " u'charact charact',\n",
       " u'charact complet',\n",
       " u'charact complex',\n",
       " ...]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check which words he memorized\n",
    "# it has too much noise\n",
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform the feature matrix `X`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TODO\n",
    "train_X = vectorizer.transform(train_X)\n",
    "test_X = vectorizer.transform(test_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1230x6272 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 79917 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X\n",
    "#spare matrix is emply matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.06615307],\n",
       "        ..., \n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "          0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.23061146, ...,  0.        ,\n",
       "          0.        ,  0.        ]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# change model here!\n",
    "#model = linear_model.LogisticRegression()\n",
    "# random forest and run all the below - check the accuracy\n",
    "#2nd Random Forest\n",
    "model = ensemble.RandomForestClassifier(n_estimators = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32769126760262807"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validation.cross_val_score(model, train_X, train_c, cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_c_hat = cross_validation.cross_val_predict(model, train_X, train_c, cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.29268292682926828"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.accuracy_score(train_c, train_c_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>True</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>92</td>\n",
       "      <td>64</td>\n",
       "      <td>40</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>48</td>\n",
       "      <td>55</td>\n",
       "      <td>44</td>\n",
       "      <td>31</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>54</td>\n",
       "      <td>60</td>\n",
       "      <td>62</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>22</td>\n",
       "      <td>60</td>\n",
       "      <td>71</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>18</td>\n",
       "      <td>29</td>\n",
       "      <td>40</td>\n",
       "      <td>84</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "True        1   2   3   4   5\n",
       "Predicted                    \n",
       "1          92  64  40  24  24\n",
       "2          48  55  44  31  33\n",
       "3          37  54  60  62  55\n",
       "4          19  22  60  71  82\n",
       "5          18  29  40  84  82"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(train_c_hat, train_c, rownames = ['Predicted'], colnames = ['True'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_X, train_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99349593495934962"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(train_X, train_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32804878048780489"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(test_X, test_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Randon Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = ensemble.RandomForestClassifier(n_estimators = 10)\n",
    "#for ten tres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.32190013458573002"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validation.cross_val_score(model, train_X, train_c, cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = ensemble.RandomForestClassifier(n_estimators = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3910050984515766"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_validation.cross_val_score(model, train_X, train_c, cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#change the ratings\n",
    "X = df.review_text\n",
    "c = df.overall.map({1: -1, 2:-1, 3:0, 4: 1, 5: 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1      -1\n",
       "2      -1\n",
       "3      -1\n",
       "4      -1\n",
       "       ..\n",
       "2045    1\n",
       "2046    0\n",
       "2047   -1\n",
       "2048    0\n",
       "2049    1\n",
       "Name: overall, dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Machine Learning Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> # TODO..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#randon forests\n",
    "#checking for feature importance see answer in the answer key\n",
    "# there is a lot of redundant words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CustomTokenizer(object):\n",
    "    def __init__(self):\n",
    "        self.stemmer = stem.porter.PorterStemmer()\n",
    "\n",
    "    def __call__(self, document):\n",
    "        tokens = tokenize_text(document)\n",
    "        tokens = Stemmer.stem_tokens(tokens)\n",
    "        return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = feature_extraction.text.TfidfVectorizer(tokenizer = CustomTokenizer(), ngram_range = (1, 3), min_df = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "lower not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-8bfbaa87089b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvectorizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/general_assembly/anaconda/lib/python2.7/site-packages/sklearn/feature_extraction/text.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m   1283\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1284\u001b[0m         \"\"\"\n\u001b[0;32m-> 1285\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTfidfVectorizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1286\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1287\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/general_assembly/anaconda/lib/python2.7/site-packages/sklearn/feature_extraction/text.pyc\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, raw_documents, y)\u001b[0m\n\u001b[1;32m    815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0;32m--> 817\u001b[0;31m                                           self.fixed_vocabulary_)\n\u001b[0m\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/general_assembly/anaconda/lib/python2.7/site-packages/sklearn/feature_extraction/text.pyc\u001b[0m in \u001b[0;36m_count_vocab\u001b[0;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[1;32m    750\u001b[0m         \u001b[0mindptr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    751\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 752\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[0;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    753\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    754\u001b[0m                     \u001b[0mj_indices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/general_assembly/anaconda/lib/python2.7/site-packages/sklearn/feature_extraction/text.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(doc)\u001b[0m\n\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m             return lambda doc: self._word_ngrams(\n\u001b[0;32m--> 238\u001b[0;31m                 tokenize(preprocess(self.decode(doc))), stop_words)\n\u001b[0m\u001b[1;32m    239\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    240\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/general_assembly/anaconda/lib/python2.7/site-packages/sklearn/feature_extraction/text.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlowercase\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstrip_accents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstrip_accents\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/general_assembly/anaconda/lib/python2.7/site-packages/scipy/sparse/base.pyc\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    523\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetnnz\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 525\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" not found\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    526\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: lower not found"
     ]
    }
   ],
   "source": [
    "vectorizer.fit(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
